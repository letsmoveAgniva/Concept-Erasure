{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8633395,"sourceType":"datasetVersion","datasetId":5169636}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-10T04:06:35.622634Z","iopub.execute_input":"2024-06-10T04:06:35.623586Z","iopub.status.idle":"2024-06-10T04:06:36.036156Z","shell.execute_reply.started":"2024-06-10T04:06:35.623553Z","shell.execute_reply":"2024-06-10T04:06:36.035115Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/bios-data/BIOS_train.csv\n/kaggle/input/bios-data/BIOS_test.csv\n/kaggle/input/bios-data/BIOS_dev.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pickle\nimport random\nimport gensim.downloader as api\n\n\nglove_model = api.load(\"glove-wiki-gigaword-100\")","metadata":{"execution":{"iopub.status.busy":"2024-06-10T04:06:37.980962Z","iopub.execute_input":"2024-06-10T04:06:37.981722Z","iopub.status.idle":"2024-06-10T04:07:45.555325Z","shell.execute_reply.started":"2024-06-10T04:06:37.981688Z","shell.execute_reply":"2024-06-10T04:07:45.554565Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"[==================================================] 100.0% 128.1/128.1MB downloaded\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n\ndef embed_text(text, model):\n\n    embeddings = [model[word] for word in text.split() if word in model.key_to_index]\n\n    if embeddings:\n        sum_embeddings = np.sum(embeddings, axis=0)\n\n        norm = np.linalg.norm(sum_embeddings)\n        if norm > 0:\n            normalized_embedding = sum_embeddings / norm\n        else:\n            normalized_embedding = sum_embeddings\n\n        return normalized_embedding\n    else:\n        return np.zeros((model.vector_size,))","metadata":{"execution":{"iopub.status.busy":"2024-06-10T04:07:45.556957Z","iopub.execute_input":"2024-06-10T04:07:45.557235Z","iopub.status.idle":"2024-06-10T04:07:45.563474Z","shell.execute_reply.started":"2024-06-10T04:07:45.557210Z","shell.execute_reply":"2024-06-10T04:07:45.562489Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"ans = embed_text('hello world and how are you', glove_model)\nans","metadata":{"execution":{"iopub.status.busy":"2024-06-10T04:07:45.564721Z","iopub.execute_input":"2024-06-10T04:07:45.565057Z","iopub.status.idle":"2024-06-10T04:07:45.585273Z","shell.execute_reply.started":"2024-06-10T04:07:45.565027Z","shell.execute_reply":"2024-06-10T04:07:45.584289Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"array([-2.03016680e-02,  1.41375616e-01,  1.25437349e-01, -9.70927253e-02,\n       -4.44688872e-02,  3.14946696e-02, -6.34306073e-02,  5.30586503e-02,\n       -2.12285761e-02, -5.19125424e-02,  8.84760469e-02, -4.36776951e-02,\n        1.03300229e-01,  2.28172522e-02,  3.29822418e-04, -4.49792445e-02,\n        4.60768491e-02,  7.27183223e-02, -1.19844139e-01,  6.31123483e-02,\n        2.19268929e-02,  3.30562145e-02,  6.00055084e-02, -1.90878063e-02,\n        7.89085552e-02,  5.22726774e-02, -3.01139653e-02, -1.08233914e-01,\n        5.68602085e-02, -2.92343795e-02, -2.93752607e-02,  1.25103652e-01,\n        3.83408321e-03,  3.39339189e-02,  5.25808111e-02,  6.22381121e-02,\n        9.16151970e-04,  6.95988685e-02,  1.03946794e-02, -8.52023885e-02,\n       -6.90805465e-02, -5.15927114e-02, -4.61702198e-02, -6.26583099e-02,\n       -5.94336130e-02,  2.00176425e-02,  3.97321209e-02, -5.84789962e-02,\n       -1.22307632e-02, -1.57907099e-01, -3.59683074e-02,  2.28246562e-02,\n        1.99170653e-02,  2.17242241e-01, -5.79234511e-02, -4.67578471e-01,\n        5.00027575e-02,  4.02349308e-02,  2.75937825e-01,  1.21502586e-01,\n       -5.08522764e-02,  2.24085838e-01, -8.42927769e-02, -4.19206768e-02,\n        1.91306919e-01,  1.18189305e-02,  1.25714630e-01,  1.07264049e-01,\n        7.44193718e-02, -9.56712738e-02,  1.49378330e-02, -6.77324459e-02,\n       -3.42057422e-02, -8.48198384e-02,  2.43621208e-02,  5.37221134e-02,\n        3.31323296e-02, -3.39809252e-04, -1.48343965e-01, -4.41576689e-02,\n        1.62181497e-01, -1.05075054e-02, -1.13775000e-01,  7.31347129e-02,\n       -3.39650035e-01, -5.67719452e-02, -3.82612795e-02, -5.09456024e-02,\n       -5.41422814e-02, -8.46858621e-02, -9.15912166e-03,  2.20062863e-02,\n        3.04958001e-02, -2.09617764e-02, -1.05357029e-01, -3.57606001e-02,\n       -8.24648812e-02, -1.10153489e-01,  9.86377448e-02,  9.25980657e-02],\n      dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\ntrain_data = pd.read_csv('/kaggle/input/bios-data/BIOS_train.csv')\ndev_data = pd.read_csv('/kaggle/input/bios-data/BIOS_dev.csv')\ntest_data = pd.read_csv('/kaggle/input/bios-data/BIOS_test.csv')\ntrain_data = train_data.drop(columns = ['Unnamed: 0'])\ndev_data = dev_data.drop(columns = ['Unnamed: 0'])\ntest_data = test_data.drop(columns = ['Unnamed: 0'])","metadata":{"execution":{"iopub.status.busy":"2024-06-10T04:07:45.587784Z","iopub.execute_input":"2024-06-10T04:07:45.588100Z","iopub.status.idle":"2024-06-10T04:07:45.761970Z","shell.execute_reply.started":"2024-06-10T04:07:45.588065Z","shell.execute_reply":"2024-06-10T04:07:45.761150Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:34:14.152907Z","iopub.execute_input":"2024-06-09T14:34:14.153746Z","iopub.status.idle":"2024-06-09T14:34:14.181095Z","shell.execute_reply.started":"2024-06-09T14:34:14.153712Z","shell.execute_reply":"2024-06-09T14:34:14.180154Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"                                                    Bio         Profession  \\\n0     _ major duties include preparing daily cash re...         accountant   \n1     _ received _ PhD in Computer Science from Cath...          professor   \n2     Dr. _ takes Blue Cross/Blue Shield, Empire Blu...          physician   \n3     In 2008, _ founded Save a Mother, which works ...          physician   \n4     One of _ short stories was commended in the Co...  software_engineer   \n...                                                 ...                ...   \n9995  _ music is based on sound manipulation created...           composer   \n9996  _. _' experience includes products liability, ...           attorney   \n9997  _ is also a coeditor of Critical Inquiry. _ sp...          professor   \n9998  _ received _ Ph.D. in Linguistics from Indiana...          professor   \n9999  _ accepts Medicare insurance. _ is a graduate ...          physician   \n\n     Gender  \n0         M  \n1         M  \n2         F  \n3         M  \n4         F  \n...     ...  \n9995      M  \n9996      M  \n9997      M  \n9998      F  \n9999      F  \n\n[10000 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Bio</th>\n      <th>Profession</th>\n      <th>Gender</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>_ major duties include preparing daily cash re...</td>\n      <td>accountant</td>\n      <td>M</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>_ received _ PhD in Computer Science from Cath...</td>\n      <td>professor</td>\n      <td>M</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Dr. _ takes Blue Cross/Blue Shield, Empire Blu...</td>\n      <td>physician</td>\n      <td>F</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>In 2008, _ founded Save a Mother, which works ...</td>\n      <td>physician</td>\n      <td>M</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>One of _ short stories was commended in the Co...</td>\n      <td>software_engineer</td>\n      <td>F</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>_ music is based on sound manipulation created...</td>\n      <td>composer</td>\n      <td>M</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>_. _' experience includes products liability, ...</td>\n      <td>attorney</td>\n      <td>M</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>_ is also a coeditor of Critical Inquiry. _ sp...</td>\n      <td>professor</td>\n      <td>M</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>_ received _ Ph.D. in Linguistics from Indiana...</td>\n      <td>professor</td>\n      <td>F</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>_ accepts Medicare insurance. _ is a graduate ...</td>\n      <td>physician</td>\n      <td>F</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_data","metadata":{"execution":{"iopub.status.busy":"2024-06-09T12:28:34.789589Z","iopub.execute_input":"2024-06-09T12:28:34.789980Z","iopub.status.idle":"2024-06-09T12:28:34.801508Z","shell.execute_reply.started":"2024-06-09T12:28:34.789950Z","shell.execute_reply":"2024-06-09T12:28:34.800663Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                                    Bio    Profession Gender\n0     _ ecocriticism has appeared in Feminist Studie...     professor      M\n1     _ has an active pediatric allergy clinic and i...     professor      F\n2     _ provides direct legal representation to ensu...      attorney      F\n3     _ joined NARF in August of 2017. Currently, _ ...      attorney      M\n4     _ was an elementary teacher and a middle level...     professor      F\n...                                                 ...           ...    ...\n1995  _. _ is the author for the Buy Batteries Direc...    journalist      M\n1996  Many of _ photographs depict landscapes and wi...  photographer      M\n1997  _ has a 1.5 out of 5 star average patient rati...     physician      M\n1998  _ graduated with honors in 1998. Having more t...         nurse      M\n1999  Dr. _ trained at the Johns Hopkins University ...     professor      M\n\n[2000 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Bio</th>\n      <th>Profession</th>\n      <th>Gender</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>_ ecocriticism has appeared in Feminist Studie...</td>\n      <td>professor</td>\n      <td>M</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>_ has an active pediatric allergy clinic and i...</td>\n      <td>professor</td>\n      <td>F</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>_ provides direct legal representation to ensu...</td>\n      <td>attorney</td>\n      <td>F</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>_ joined NARF in August of 2017. Currently, _ ...</td>\n      <td>attorney</td>\n      <td>M</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>_ was an elementary teacher and a middle level...</td>\n      <td>professor</td>\n      <td>F</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>_. _ is the author for the Buy Batteries Direc...</td>\n      <td>journalist</td>\n      <td>M</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>Many of _ photographs depict landscapes and wi...</td>\n      <td>photographer</td>\n      <td>M</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>_ has a 1.5 out of 5 star average patient rati...</td>\n      <td>physician</td>\n      <td>M</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>_ graduated with honors in 1998. Having more t...</td>\n      <td>nurse</td>\n      <td>M</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>Dr. _ trained at the Johns Hopkins University ...</td>\n      <td>professor</td>\n      <td>M</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"dev_data","metadata":{"execution":{"iopub.status.busy":"2024-06-09T12:28:53.723260Z","iopub.execute_input":"2024-06-09T12:28:53.723952Z","iopub.status.idle":"2024-06-09T12:28:53.736179Z","shell.execute_reply.started":"2024-06-09T12:28:53.723919Z","shell.execute_reply":"2024-06-09T12:28:53.735204Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                                    Bio    Profession Gender\n0     _ research interests include topics such as mo...     professor      F\n1     _ and Alexander George, a professor of philoso...     professor      M\n2     _ worked with students with Special Educationa...       teacher      F\n3     _ worked for The Guardian for 32 years, becomi...    journalist      M\n4     After starting _ career in Paris, _ now writes...    journalist      F\n...                                                 ...           ...    ...\n1995  _ has expertise in all aspects of arthritis tr...       surgeon      M\n1996  Dr. _ earned a masters of Science in Biotechno...     professor      F\n1997  _ also serves as the Program Coordinator for t...     professor      M\n1998  _ subjects include still lifes filled with hei...       painter      F\n1999  _ graduated with honors in 2008. Having more t...  psychologist      F\n\n[2000 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Bio</th>\n      <th>Profession</th>\n      <th>Gender</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>_ research interests include topics such as mo...</td>\n      <td>professor</td>\n      <td>F</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>_ and Alexander George, a professor of philoso...</td>\n      <td>professor</td>\n      <td>M</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>_ worked with students with Special Educationa...</td>\n      <td>teacher</td>\n      <td>F</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>_ worked for The Guardian for 32 years, becomi...</td>\n      <td>journalist</td>\n      <td>M</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>After starting _ career in Paris, _ now writes...</td>\n      <td>journalist</td>\n      <td>F</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>_ has expertise in all aspects of arthritis tr...</td>\n      <td>surgeon</td>\n      <td>M</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>Dr. _ earned a masters of Science in Biotechno...</td>\n      <td>professor</td>\n      <td>F</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>_ also serves as the Program Coordinator for t...</td>\n      <td>professor</td>\n      <td>M</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>_ subjects include still lifes filled with hei...</td>\n      <td>painter</td>\n      <td>F</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>_ graduated with honors in 2008. Having more t...</td>\n      <td>psychologist</td>\n      <td>F</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# !pip install nltk","metadata":{"execution":{"iopub.status.busy":"2024-06-09T12:31:09.425434Z","iopub.execute_input":"2024-06-09T12:31:09.425798Z","iopub.status.idle":"2024-06-09T12:31:21.995409Z","shell.execute_reply.started":"2024-06-09T12:31:09.425758Z","shell.execute_reply":"2024-06-09T12:31:21.994467Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"# import re\n# import string\n# from nltk.tokenize import word_tokenize\n# from nltk.corpus import stopwords\n# from nltk.stem import WordNetLemmatizer\n# from nltk import pos_tag\n# import nltk\n\n# def preprocess_tweet(tweet):\n\n#     tweet = tweet.lower()\n\n#     tweet = re.sub(r'http\\S+', '', tweet)\n#     tweet = re.sub(r'www\\S+', '', tweet)\n\n#     tweet = re.sub(r'#\\w+', '', tweet)\n#     tweet = re.sub(r'@\\w+', '', tweet)\n\n#     tweet = tweet.translate(str.maketrans('', '', string.punctuation))\n\n#     tweet = re.sub(r'\\s+', ' ', tweet).strip()\n\n\n#     tokens = word_tokenize(tweet)\n\n#     stop_words = set(stopwords.words('english'))\n#     lemmatizer = WordNetLemmatizer()\n\n#     clean_tokens = []\n#     for token, tag in pos_tag(tokens):\n#         if token.isalpha() and token not in stop_words:\n#             if tag.startswith('N') or tag.startswith('J'):\n#                 clean_tokens.append(lemmatizer.lemmatize(token))\n\n\n#     return ' '.join(clean_tokens)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('averaged_perceptron_tagger')\nnltk.download('wordnet')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nltk.download('all')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-09T12:33:12.251895Z","iopub.execute_input":"2024-06-09T12:33:12.252523Z","iopub.status.idle":"2024-06-09T12:33:28.128692Z","shell.execute_reply.started":"2024-06-09T12:33:12.252485Z","shell.execute_reply":"2024-06-09T12:33:28.127407Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading collection 'all'\n[nltk_data]    | \n[nltk_data]    | Downloading package abc to /usr/share/nltk_data...\n[nltk_data]    |   Package abc is already up-to-date!\n[nltk_data]    | Downloading package alpino to /usr/share/nltk_data...\n[nltk_data]    |   Package alpino is already up-to-date!\n[nltk_data]    | Downloading package averaged_perceptron_tagger to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n[nltk_data]    |       to-date!\n[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Unzipping\n[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n[nltk_data]    | Downloading package basque_grammars to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package basque_grammars is already up-to-date!\n[nltk_data]    | Downloading package bcp47 to /usr/share/nltk_data...\n[nltk_data]    | Downloading package biocreative_ppi to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n[nltk_data]    | Downloading package bllip_wsj_no_aux to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n[nltk_data]    | Downloading package book_grammars to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package book_grammars is already up-to-date!\n[nltk_data]    | Downloading package brown to /usr/share/nltk_data...\n[nltk_data]    |   Package brown is already up-to-date!\n[nltk_data]    | Downloading package brown_tei to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package brown_tei is already up-to-date!\n[nltk_data]    | Downloading package cess_cat to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package cess_cat is already up-to-date!\n[nltk_data]    | Downloading package cess_esp to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package cess_esp is already up-to-date!\n[nltk_data]    | Downloading package chat80 to /usr/share/nltk_data...\n[nltk_data]    |   Package chat80 is already up-to-date!\n[nltk_data]    | Downloading package city_database to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package city_database is already up-to-date!\n[nltk_data]    | Downloading package cmudict to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package cmudict is already up-to-date!\n[nltk_data]    | Downloading package comparative_sentences to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n[nltk_data]    | Downloading package comtrans to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package comtrans is already up-to-date!\n[nltk_data]    | Downloading package conll2000 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package conll2000 is already up-to-date!\n[nltk_data]    | Downloading package conll2002 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package conll2002 is already up-to-date!\n[nltk_data]    | Downloading package conll2007 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package conll2007 is already up-to-date!\n[nltk_data]    | Downloading package crubadan to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package crubadan is already up-to-date!\n[nltk_data]    | Downloading package dependency_treebank to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package dependency_treebank is already up-to-date!\n[nltk_data]    | Downloading package dolch to /usr/share/nltk_data...\n[nltk_data]    |   Unzipping corpora/dolch.zip.\n[nltk_data]    | Downloading package europarl_raw to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package europarl_raw is already up-to-date!\n[nltk_data]    | Downloading package extended_omw to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    | Downloading package floresta to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package floresta is already up-to-date!\n[nltk_data]    | Downloading package framenet_v15 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n[nltk_data]    | Downloading package framenet_v17 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n[nltk_data]    | Downloading package gazetteers to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package gazetteers is already up-to-date!\n[nltk_data]    | Downloading package genesis to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package genesis is already up-to-date!\n[nltk_data]    | Downloading package gutenberg to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package gutenberg is already up-to-date!\n[nltk_data]    | Downloading package ieer to /usr/share/nltk_data...\n[nltk_data]    |   Package ieer is already up-to-date!\n[nltk_data]    | Downloading package inaugural to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package inaugural is already up-to-date!\n[nltk_data]    | Downloading package indian to /usr/share/nltk_data...\n[nltk_data]    |   Package indian is already up-to-date!\n[nltk_data]    | Downloading package jeita to /usr/share/nltk_data...\n[nltk_data]    |   Package jeita is already up-to-date!\n[nltk_data]    | Downloading package kimmo to /usr/share/nltk_data...\n[nltk_data]    |   Package kimmo is already up-to-date!\n[nltk_data]    | Downloading package knbc to /usr/share/nltk_data...\n[nltk_data]    |   Package knbc is already up-to-date!\n[nltk_data]    | Downloading package large_grammars to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package large_grammars is already up-to-date!\n[nltk_data]    | Downloading package lin_thesaurus to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n[nltk_data]    | Downloading package mac_morpho to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package mac_morpho is already up-to-date!\n[nltk_data]    | Downloading package machado to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package machado is already up-to-date!\n[nltk_data]    | Downloading package masc_tagged to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package masc_tagged is already up-to-date!\n[nltk_data]    | Downloading package maxent_ne_chunker to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n[nltk_data]    |       to-date!\n[nltk_data]    | Downloading package moses_sample to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package moses_sample is already up-to-date!\n[nltk_data]    | Downloading package movie_reviews to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package movie_reviews is already up-to-date!\n[nltk_data]    | Downloading package mte_teip5 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package mte_teip5 is already up-to-date!\n[nltk_data]    | Downloading package mwa_ppdb to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n[nltk_data]    | Downloading package names to /usr/share/nltk_data...\n[nltk_data]    |   Package names is already up-to-date!\n[nltk_data]    | Downloading package nombank.1.0 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    | Downloading package nonbreaking_prefixes to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n[nltk_data]    | Downloading package nps_chat to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package nps_chat is already up-to-date!\n[nltk_data]    | Downloading package omw to /usr/share/nltk_data...\n[nltk_data]    |   Package omw is already up-to-date!\n[nltk_data]    | Downloading package omw-1.4 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    | Downloading package opinion_lexicon to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n[nltk_data]    | Downloading package panlex_swadesh to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    | Downloading package paradigms to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package paradigms is already up-to-date!\n[nltk_data]    | Downloading package pe08 to /usr/share/nltk_data...\n[nltk_data]    |   Unzipping corpora/pe08.zip.\n[nltk_data]    | Downloading package perluniprops to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Unzipping misc/perluniprops.zip.\n[nltk_data]    | Downloading package pil to /usr/share/nltk_data...\n[nltk_data]    |   Package pil is already up-to-date!\n[nltk_data]    | Downloading package pl196x to /usr/share/nltk_data...\n[nltk_data]    |   Package pl196x is already up-to-date!\n[nltk_data]    | Downloading package porter_test to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package porter_test is already up-to-date!\n[nltk_data]    | Downloading package ppattach to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package ppattach is already up-to-date!\n[nltk_data]    | Downloading package problem_reports to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package problem_reports is already up-to-date!\n[nltk_data]    | Downloading package product_reviews_1 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n[nltk_data]    | Downloading package product_reviews_2 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n[nltk_data]    | Downloading package propbank to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package propbank is already up-to-date!\n[nltk_data]    | Downloading package pros_cons to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package pros_cons is already up-to-date!\n[nltk_data]    | Downloading package ptb to /usr/share/nltk_data...\n[nltk_data]    |   Package ptb is already up-to-date!\n[nltk_data]    | Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]    |   Package punkt is already up-to-date!\n[nltk_data]    | Downloading package qc to /usr/share/nltk_data...\n[nltk_data]    |   Package qc is already up-to-date!\n[nltk_data]    | Downloading package reuters to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package reuters is already up-to-date!\n[nltk_data]    | Downloading package rslp to /usr/share/nltk_data...\n[nltk_data]    |   Package rslp is already up-to-date!\n[nltk_data]    | Downloading package rte to /usr/share/nltk_data...\n[nltk_data]    |   Package rte is already up-to-date!\n[nltk_data]    | Downloading package sample_grammars to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package sample_grammars is already up-to-date!\n[nltk_data]    | Downloading package semcor to /usr/share/nltk_data...\n[nltk_data]    |   Package semcor is already up-to-date!\n[nltk_data]    | Downloading package senseval to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package senseval is already up-to-date!\n[nltk_data]    | Downloading package sentence_polarity to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package sentence_polarity is already up-to-date!\n[nltk_data]    | Downloading package sentiwordnet to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package sentiwordnet is already up-to-date!\n[nltk_data]    | Downloading package shakespeare to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package shakespeare is already up-to-date!\n[nltk_data]    | Downloading package sinica_treebank to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package sinica_treebank is already up-to-date!\n[nltk_data]    | Downloading package smultron to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package smultron is already up-to-date!\n[nltk_data]    | Downloading package snowball_data to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package snowball_data is already up-to-date!\n[nltk_data]    | Downloading package spanish_grammars to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package spanish_grammars is already up-to-date!\n[nltk_data]    | Downloading package state_union to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package state_union is already up-to-date!\n[nltk_data]    | Downloading package stopwords to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package stopwords is already up-to-date!\n[nltk_data]    | Downloading package subjectivity to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package subjectivity is already up-to-date!\n[nltk_data]    | Downloading package swadesh to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package swadesh is already up-to-date!\n[nltk_data]    | Downloading package switchboard to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package switchboard is already up-to-date!\n[nltk_data]    | Downloading package tagsets to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package tagsets is already up-to-date!\n[nltk_data]    | Downloading package timit to /usr/share/nltk_data...\n[nltk_data]    |   Package timit is already up-to-date!\n[nltk_data]    | Downloading package toolbox to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package toolbox is already up-to-date!\n[nltk_data]    | Downloading package treebank to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package treebank is already up-to-date!\n[nltk_data]    | Downloading package twitter_samples to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package twitter_samples is already up-to-date!\n[nltk_data]    | Downloading package udhr to /usr/share/nltk_data...\n[nltk_data]    |   Package udhr is already up-to-date!\n[nltk_data]    | Downloading package udhr2 to /usr/share/nltk_data...\n[nltk_data]    |   Package udhr2 is already up-to-date!\n[nltk_data]    | Downloading package unicode_samples to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package unicode_samples is already up-to-date!\n[nltk_data]    | Downloading package universal_tagset to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package universal_tagset is already up-to-date!\n[nltk_data]    | Downloading package universal_treebanks_v20 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n[nltk_data]    |       date!\n[nltk_data]    | Downloading package vader_lexicon to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package vader_lexicon is already up-to-date!\n[nltk_data]    | Downloading package verbnet to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package verbnet is already up-to-date!\n[nltk_data]    | Downloading package verbnet3 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n[nltk_data]    | Downloading package webtext to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package webtext is already up-to-date!\n[nltk_data]    | Downloading package wmt15_eval to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n[nltk_data]    | Downloading package word2vec_sample to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package word2vec_sample is already up-to-date!\n[nltk_data]    | Downloading package wordnet to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package wordnet is already up-to-date!\n[nltk_data]    | Downloading package wordnet2021 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    | Downloading package wordnet2022 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n[nltk_data]    | Downloading package wordnet31 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    | Downloading package wordnet_ic to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package wordnet_ic is already up-to-date!\n[nltk_data]    | Downloading package words to /usr/share/nltk_data...\n[nltk_data]    |   Package words is already up-to-date!\n[nltk_data]    | Downloading package ycoe to /usr/share/nltk_data...\n[nltk_data]    |   Package ycoe is already up-to-date!\n[nltk_data]    | \n[nltk_data]  Done downloading collection all\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"# train_data['Bio'] = train_data['Bio'].apply(preprocess_tweet)\n# dev_data['Bio'] = dev_data['Bio'].apply(preprocess_tweet)\n# test_data['Bio'] = test_data['Bio'].apply(preprocess_tweet)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T12:34:40.845250Z","iopub.execute_input":"2024-06-09T12:34:40.845851Z","iopub.status.idle":"2024-06-09T12:34:41.062290Z","shell.execute_reply.started":"2024-06-09T12:34:40.845819Z","shell.execute_reply":"2024-06-09T12:34:41.061021Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":16,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/corpus/util.py:80\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzip_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m: \u001b[38;5;28;01mraise\u001b[39;00m e\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/data.py:653\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    652\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (sep, msg, sep)\n\u001b[0;32m--> 653\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n","\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource 'corpora/wordnet.zip/wordnet/.zip/' not found.  Please\n  use the NLTK Downloader to obtain the resource:  >>>\n  nltk.download()\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBio\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBio\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess_tweet\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m dev_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBio\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m dev_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBio\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(preprocess_tweet)\n\u001b[1;32m      3\u001b[0m test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBio\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBio\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(preprocess_tweet)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n","File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n","Cell \u001b[0;32mIn[10], line 33\u001b[0m, in \u001b[0;36mpreprocess_tweet\u001b[0;34m(tweet)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m token\u001b[38;5;241m.\u001b[39misalpha() \u001b[38;5;129;01mand\u001b[39;00m token \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m stop_words:\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m tag\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m tag\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJ\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 33\u001b[0m             clean_tokens\u001b[38;5;241m.\u001b[39mappend(\u001b[43mlemmatizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlemmatize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(clean_tokens)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/stem/wordnet.py:40\u001b[0m, in \u001b[0;36mWordNetLemmatizer.lemmatize\u001b[0;34m(self, word, pos)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlemmatize\u001b[39m(\u001b[38;5;28mself\u001b[39m, word, pos\u001b[38;5;241m=\u001b[39mNOUN):\n\u001b[0;32m---> 40\u001b[0m     lemmas \u001b[38;5;241m=\u001b[39m \u001b[43mwordnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_morphy\u001b[49m(word, pos)\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(lemmas, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m lemmas \u001b[38;5;28;01melse\u001b[39;00m word\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/corpus/util.py:116\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLazyCorpusLoader object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 116\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# __class__ to something new:\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/corpus/util.py:81\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m: root \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubdir, zip_name))\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m: \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Load the corpus.\u001b[39;00m\n\u001b[1;32m     84\u001b[0m corpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__reader_cls(root, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__kwargs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/corpus/util.py:78\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m         root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m: root \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubdir, zip_name))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/data.py:653\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    651\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    652\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (sep, msg, sep)\n\u001b[0;32m--> 653\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n","\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource 'corpora/wordnet' not found.  Please use the NLTK\n  Downloader to obtain the resource:  >>> nltk.download()\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************"],"ename":"LookupError","evalue":"\n**********************************************************************\n  Resource 'corpora/wordnet' not found.  Please use the NLTK\n  Downloader to obtain the resource:  >>> nltk.download()\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************","output_type":"error"}]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder, LabelEncoder\ndef preprocess_data(data):\n    embedded_data = []\n    X_all, words_train_all = [], []\n    Y_all = []\n    for _, row in data.iterrows():\n        bio_embedding = embed_text(row['Bio'], glove_model)\n        X_all.append(row['Profession'])\n        words_train_all.append(bio_embedding)\n        embedded_data.append(bio_embedding)\n        Y_all.append(row['Gender'])\n    # encoder = OneHotEncoder(sparse=False)\n    label = LabelEncoder()\n    X_all_encoded = label.fit_transform(np.array(X_all).reshape(-1, 1))\n    Y_all_encoded = label.fit_transform(np.array(Y_all).reshape(-1, 1))\n\n\n    # words_train_all = np.array(words_train_all)\n\n    return embedded_data , Y_all_encoded, X_all_encoded, words_train_all\n\nX_train, Y_train, profession, words_train_train = preprocess_data(train_data)\nX_dev, Y_dev, profession_dev, words_train_dev = preprocess_data(dev_data)\nX_test, Y_test, profession_test, words_train_test = preprocess_data(test_data)\n\n\nmax_length = max(len(sublist) for sublist in X_train)\n\nX_train_padded = [np.pad(sublist, (0, max_length - len(sublist)), 'constant', constant_values=0) for sublist in X_train]\n\nX_train = np.array(X_train_padded)\n\nmax_length = max(len(sublist) for sublist in X_dev)\n\nX_dev_padded = [np.pad(sublist, (0, max_length - len(sublist)), 'constant', constant_values=0) for sublist in X_dev]\n\nX_dev = np.array(X_dev_padded)\n\nmax_length = max(len(sublist) for sublist in X_test)\n\nX_test_padded = [np.pad(sublist, (0, max_length - len(sublist)), 'constant', constant_values=0) for sublist in X_test]\n\nX_test = np.array(X_test_padded)\n\n\nglove_gender_data = {\n    \"train\": (X_train, Y_train,profession, words_train_train),\n    \"dev\": (X_dev, Y_dev,profession_dev, words_train_dev),\n    \"test\": (X_test, Y_test,profession_test, words_train_test)\n}\n\n# with open('glove-gender-data.pickle', 'wb') as f:\n#     pickle.dump(glove_gender_data, f)","metadata":{"execution":{"iopub.status.busy":"2024-06-10T04:07:45.763532Z","iopub.execute_input":"2024-06-10T04:07:45.763924Z","iopub.status.idle":"2024-06-10T04:07:49.489459Z","shell.execute_reply.started":"2024-06-10T04:07:45.763889Z","shell.execute_reply":"2024-06-10T04:07:49.488680Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n","output_type":"stream"}]},{"cell_type":"code","source":"\nwith open('glove-gender-data.pickle', 'wb') as f:\n    pickle.dump(glove_gender_data, f)","metadata":{"execution":{"iopub.status.busy":"2024-06-10T04:07:49.490582Z","iopub.execute_input":"2024-06-10T04:07:49.490935Z","iopub.status.idle":"2024-06-10T04:07:49.578694Z","shell.execute_reply.started":"2024-06-10T04:07:49.490903Z","shell.execute_reply":"2024-06-10T04:07:49.577973Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\n\nclass MultitaskMLP(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size_gender, output_size_profession):\n        super(MultitaskMLP, self).__init__()\n        # Shared layers\n        self.shared_fc1 = nn.Linear(input_size, hidden_size)\n        self.shared_bn1 = nn.BatchNorm1d(hidden_size)\n        self.shared_relu = nn.ReLU()\n\n        # Task-specific layers\n        self.fc_gender = nn.Linear(hidden_size, output_size_gender)\n        self.fc_profession = nn.Linear(hidden_size, output_size_profession)\n    \n    def forward(self, x):\n        # Shared layers\n        x = self.shared_fc1(x)\n        x = self.shared_bn1(x)\n        x = self.shared_relu(x)\n\n        # Task-specific outputs\n        gender_output = self.fc_gender(x)\n        profession_output = self.fc_profession(x)\n        \n        return gender_output, profession_output\n","metadata":{"execution":{"iopub.status.busy":"2024-06-10T04:07:49.579667Z","iopub.execute_input":"2024-06-10T04:07:49.579951Z","iopub.status.idle":"2024-06-10T04:07:49.588057Z","shell.execute_reply.started":"2024-06-10T04:07:49.579927Z","shell.execute_reply":"2024-06-10T04:07:49.587086Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"input_size = X_train.shape[1]\nhidden_size = 128\noutput_size_gender = len(np.unique(Y_train))\noutput_size_profession = len(np.unique(profession))\ndef train_multitask_model(model, train_loader, criterion_gender, criterion_profession, optimizer, num_epochs=10):\n    model.train()\n    for epoch in range(num_epochs):\n        total_loss_gender = 0\n        total_loss_profession = 0\n        for batch_X, batch_Y_gender, batch_Y_profession in train_loader:\n            optimizer.zero_grad()\n            outputs_gender, outputs_profession = model(batch_X)\n            loss_gender = criterion_gender(outputs_gender, batch_Y_gender)\n            loss_profession = criterion_profession(outputs_profession, batch_Y_profession)\n            total_loss = loss_gender + loss_profession\n            total_loss.backward()\n            optimizer.step()\n            total_loss_gender += loss_gender.item()\n            total_loss_profession += loss_profession.item()\n        \n        avg_loss_gender = total_loss_gender / len(train_loader)\n        avg_loss_profession = total_loss_profession / len(train_loader)\n        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss Gender: {avg_loss_gender:.4f}, Loss Profession: {avg_loss_profession:.4f}\")\n# Combine the datasets into a single multitask dataset\nX_train_tensor = torch.tensor(X_train, dtype=torch.float32)\nY_train_tensor = torch.tensor(Y_train, dtype=torch.long)\nprofession_train_tensor = torch.tensor(profession, dtype=torch.long)\n\nX_dev_tensor = torch.tensor(X_dev, dtype=torch.float32)\nY_dev_tensor = torch.tensor(Y_dev, dtype=torch.long)\nprofession_dev_tensor = torch.tensor(profession_dev, dtype=torch.long)\n\n\n\ntrain_dataset_multitask = TensorDataset(X_train_tensor, Y_train_tensor, profession_train_tensor)\ndev_dataset_multitask = TensorDataset(X_dev_tensor, Y_dev_tensor, profession_dev_tensor)\n\ntrain_loader_multitask = DataLoader(train_dataset_multitask, batch_size=32, shuffle=True)\ndev_loader_multitask = DataLoader(dev_dataset_multitask, batch_size=32, shuffle=False)\n# Define loss functions for both tasks\ncriterion_gender = nn.CrossEntropyLoss()\ncriterion_profession = nn.CrossEntropyLoss()\n\n# Create model and optimizer\nmodel_multitask = MultitaskMLP(input_size, hidden_size, output_size_gender, output_size_profession)\noptimizer_multitask = optim.SGD(model_multitask.parameters(), lr=0.001)\n# Train the multitask model\ntrain_multitask_model(model_multitask, train_loader_multitask, criterion_gender, criterion_profession, optimizer_multitask, num_epochs=150)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-10T04:19:57.829655Z","iopub.execute_input":"2024-06-10T04:19:57.830287Z","iopub.status.idle":"2024-06-10T04:21:13.333516Z","shell.execute_reply.started":"2024-06-10T04:19:57.830258Z","shell.execute_reply":"2024-06-10T04:21:13.332567Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Epoch [1/150], Loss Gender: 0.7098, Loss Profession: 3.0957\nEpoch [2/150], Loss Gender: 0.6810, Loss Profession: 2.6618\nEpoch [3/150], Loss Gender: 0.6702, Loss Profession: 2.4592\nEpoch [4/150], Loss Gender: 0.6626, Loss Profession: 2.3351\nEpoch [5/150], Loss Gender: 0.6582, Loss Profession: 2.2399\nEpoch [6/150], Loss Gender: 0.6540, Loss Profession: 2.1687\nEpoch [7/150], Loss Gender: 0.6517, Loss Profession: 2.1107\nEpoch [8/150], Loss Gender: 0.6490, Loss Profession: 2.0639\nEpoch [9/150], Loss Gender: 0.6471, Loss Profession: 2.0229\nEpoch [10/150], Loss Gender: 0.6449, Loss Profession: 1.9850\nEpoch [11/150], Loss Gender: 0.6445, Loss Profession: 1.9541\nEpoch [12/150], Loss Gender: 0.6419, Loss Profession: 1.9235\nEpoch [13/150], Loss Gender: 0.6415, Loss Profession: 1.8999\nEpoch [14/150], Loss Gender: 0.6394, Loss Profession: 1.8746\nEpoch [15/150], Loss Gender: 0.6392, Loss Profession: 1.8510\nEpoch [16/150], Loss Gender: 0.6366, Loss Profession: 1.8290\nEpoch [17/150], Loss Gender: 0.6366, Loss Profession: 1.8087\nEpoch [18/150], Loss Gender: 0.6350, Loss Profession: 1.7852\nEpoch [19/150], Loss Gender: 0.6337, Loss Profession: 1.7667\nEpoch [20/150], Loss Gender: 0.6344, Loss Profession: 1.7525\nEpoch [21/150], Loss Gender: 0.6323, Loss Profession: 1.7338\nEpoch [22/150], Loss Gender: 0.6321, Loss Profession: 1.7150\nEpoch [23/150], Loss Gender: 0.6303, Loss Profession: 1.7034\nEpoch [24/150], Loss Gender: 0.6307, Loss Profession: 1.6914\nEpoch [25/150], Loss Gender: 0.6301, Loss Profession: 1.6726\nEpoch [26/150], Loss Gender: 0.6294, Loss Profession: 1.6596\nEpoch [27/150], Loss Gender: 0.6287, Loss Profession: 1.6466\nEpoch [28/150], Loss Gender: 0.6283, Loss Profession: 1.6359\nEpoch [29/150], Loss Gender: 0.6283, Loss Profession: 1.6205\nEpoch [30/150], Loss Gender: 0.6257, Loss Profession: 1.6148\nEpoch [31/150], Loss Gender: 0.6261, Loss Profession: 1.6015\nEpoch [32/150], Loss Gender: 0.6269, Loss Profession: 1.5907\nEpoch [33/150], Loss Gender: 0.6261, Loss Profession: 1.5810\nEpoch [34/150], Loss Gender: 0.6254, Loss Profession: 1.5693\nEpoch [35/150], Loss Gender: 0.6239, Loss Profession: 1.5601\nEpoch [36/150], Loss Gender: 0.6229, Loss Profession: 1.5541\nEpoch [37/150], Loss Gender: 0.6227, Loss Profession: 1.5380\nEpoch [38/150], Loss Gender: 0.6236, Loss Profession: 1.5354\nEpoch [39/150], Loss Gender: 0.6231, Loss Profession: 1.5235\nEpoch [40/150], Loss Gender: 0.6216, Loss Profession: 1.5143\nEpoch [41/150], Loss Gender: 0.6222, Loss Profession: 1.5108\nEpoch [42/150], Loss Gender: 0.6205, Loss Profession: 1.4965\nEpoch [43/150], Loss Gender: 0.6216, Loss Profession: 1.4933\nEpoch [44/150], Loss Gender: 0.6205, Loss Profession: 1.4876\nEpoch [45/150], Loss Gender: 0.6202, Loss Profession: 1.4800\nEpoch [46/150], Loss Gender: 0.6204, Loss Profession: 1.4681\nEpoch [47/150], Loss Gender: 0.6185, Loss Profession: 1.4628\nEpoch [48/150], Loss Gender: 0.6173, Loss Profession: 1.4585\nEpoch [49/150], Loss Gender: 0.6178, Loss Profession: 1.4558\nEpoch [50/150], Loss Gender: 0.6182, Loss Profession: 1.4477\nEpoch [51/150], Loss Gender: 0.6161, Loss Profession: 1.4334\nEpoch [52/150], Loss Gender: 0.6175, Loss Profession: 1.4358\nEpoch [53/150], Loss Gender: 0.6164, Loss Profession: 1.4276\nEpoch [54/150], Loss Gender: 0.6161, Loss Profession: 1.4236\nEpoch [55/150], Loss Gender: 0.6152, Loss Profession: 1.4176\nEpoch [56/150], Loss Gender: 0.6149, Loss Profession: 1.4108\nEpoch [57/150], Loss Gender: 0.6136, Loss Profession: 1.4065\nEpoch [58/150], Loss Gender: 0.6134, Loss Profession: 1.3960\nEpoch [59/150], Loss Gender: 0.6145, Loss Profession: 1.3940\nEpoch [60/150], Loss Gender: 0.6137, Loss Profession: 1.3905\nEpoch [61/150], Loss Gender: 0.6135, Loss Profession: 1.3857\nEpoch [62/150], Loss Gender: 0.6118, Loss Profession: 1.3827\nEpoch [63/150], Loss Gender: 0.6121, Loss Profession: 1.3707\nEpoch [64/150], Loss Gender: 0.6123, Loss Profession: 1.3675\nEpoch [65/150], Loss Gender: 0.6101, Loss Profession: 1.3650\nEpoch [66/150], Loss Gender: 0.6115, Loss Profession: 1.3592\nEpoch [67/150], Loss Gender: 0.6098, Loss Profession: 1.3582\nEpoch [68/150], Loss Gender: 0.6114, Loss Profession: 1.3514\nEpoch [69/150], Loss Gender: 0.6095, Loss Profession: 1.3434\nEpoch [70/150], Loss Gender: 0.6075, Loss Profession: 1.3452\nEpoch [71/150], Loss Gender: 0.6097, Loss Profession: 1.3459\nEpoch [72/150], Loss Gender: 0.6089, Loss Profession: 1.3325\nEpoch [73/150], Loss Gender: 0.6071, Loss Profession: 1.3394\nEpoch [74/150], Loss Gender: 0.6061, Loss Profession: 1.3272\nEpoch [75/150], Loss Gender: 0.6079, Loss Profession: 1.3227\nEpoch [76/150], Loss Gender: 0.6058, Loss Profession: 1.3189\nEpoch [77/150], Loss Gender: 0.6055, Loss Profession: 1.3186\nEpoch [78/150], Loss Gender: 0.6061, Loss Profession: 1.3175\nEpoch [79/150], Loss Gender: 0.6064, Loss Profession: 1.3087\nEpoch [80/150], Loss Gender: 0.6049, Loss Profession: 1.3066\nEpoch [81/150], Loss Gender: 0.6045, Loss Profession: 1.3032\nEpoch [82/150], Loss Gender: 0.6054, Loss Profession: 1.3001\nEpoch [83/150], Loss Gender: 0.6043, Loss Profession: 1.2921\nEpoch [84/150], Loss Gender: 0.6044, Loss Profession: 1.2918\nEpoch [85/150], Loss Gender: 0.6048, Loss Profession: 1.2876\nEpoch [86/150], Loss Gender: 0.6031, Loss Profession: 1.2863\nEpoch [87/150], Loss Gender: 0.6026, Loss Profession: 1.2845\nEpoch [88/150], Loss Gender: 0.6020, Loss Profession: 1.2777\nEpoch [89/150], Loss Gender: 0.6039, Loss Profession: 1.2773\nEpoch [90/150], Loss Gender: 0.6013, Loss Profession: 1.2766\nEpoch [91/150], Loss Gender: 0.6008, Loss Profession: 1.2690\nEpoch [92/150], Loss Gender: 0.6013, Loss Profession: 1.2686\nEpoch [93/150], Loss Gender: 0.5995, Loss Profession: 1.2680\nEpoch [94/150], Loss Gender: 0.6005, Loss Profession: 1.2683\nEpoch [95/150], Loss Gender: 0.6004, Loss Profession: 1.2609\nEpoch [96/150], Loss Gender: 0.5996, Loss Profession: 1.2565\nEpoch [97/150], Loss Gender: 0.5990, Loss Profession: 1.2511\nEpoch [98/150], Loss Gender: 0.6003, Loss Profession: 1.2511\nEpoch [99/150], Loss Gender: 0.5995, Loss Profession: 1.2480\nEpoch [100/150], Loss Gender: 0.6002, Loss Profession: 1.2458\nEpoch [101/150], Loss Gender: 0.5968, Loss Profession: 1.2454\nEpoch [102/150], Loss Gender: 0.5968, Loss Profession: 1.2420\nEpoch [103/150], Loss Gender: 0.5978, Loss Profession: 1.2374\nEpoch [104/150], Loss Gender: 0.5960, Loss Profession: 1.2350\nEpoch [105/150], Loss Gender: 0.5959, Loss Profession: 1.2375\nEpoch [106/150], Loss Gender: 0.5972, Loss Profession: 1.2371\nEpoch [107/150], Loss Gender: 0.5964, Loss Profession: 1.2290\nEpoch [108/150], Loss Gender: 0.5924, Loss Profession: 1.2255\nEpoch [109/150], Loss Gender: 0.5964, Loss Profession: 1.2222\nEpoch [110/150], Loss Gender: 0.5944, Loss Profession: 1.2265\nEpoch [111/150], Loss Gender: 0.5956, Loss Profession: 1.2188\nEpoch [112/150], Loss Gender: 0.5946, Loss Profession: 1.2146\nEpoch [113/150], Loss Gender: 0.5931, Loss Profession: 1.2126\nEpoch [114/150], Loss Gender: 0.5938, Loss Profession: 1.2128\nEpoch [115/150], Loss Gender: 0.5932, Loss Profession: 1.2149\nEpoch [116/150], Loss Gender: 0.5929, Loss Profession: 1.2078\nEpoch [117/150], Loss Gender: 0.5921, Loss Profession: 1.2052\nEpoch [118/150], Loss Gender: 0.5944, Loss Profession: 1.2041\nEpoch [119/150], Loss Gender: 0.5916, Loss Profession: 1.1975\nEpoch [120/150], Loss Gender: 0.5925, Loss Profession: 1.1952\nEpoch [121/150], Loss Gender: 0.5921, Loss Profession: 1.1963\nEpoch [122/150], Loss Gender: 0.5898, Loss Profession: 1.1968\nEpoch [123/150], Loss Gender: 0.5911, Loss Profession: 1.1981\nEpoch [124/150], Loss Gender: 0.5896, Loss Profession: 1.1891\nEpoch [125/150], Loss Gender: 0.5914, Loss Profession: 1.1826\nEpoch [126/150], Loss Gender: 0.5886, Loss Profession: 1.1850\nEpoch [127/150], Loss Gender: 0.5914, Loss Profession: 1.1826\nEpoch [128/150], Loss Gender: 0.5886, Loss Profession: 1.1797\nEpoch [129/150], Loss Gender: 0.5895, Loss Profession: 1.1848\nEpoch [130/150], Loss Gender: 0.5882, Loss Profession: 1.1719\nEpoch [131/150], Loss Gender: 0.5886, Loss Profession: 1.1788\nEpoch [132/150], Loss Gender: 0.5890, Loss Profession: 1.1715\nEpoch [133/150], Loss Gender: 0.5881, Loss Profession: 1.1741\nEpoch [134/150], Loss Gender: 0.5865, Loss Profession: 1.1709\nEpoch [135/150], Loss Gender: 0.5889, Loss Profession: 1.1691\nEpoch [136/150], Loss Gender: 0.5852, Loss Profession: 1.1658\nEpoch [137/150], Loss Gender: 0.5860, Loss Profession: 1.1615\nEpoch [138/150], Loss Gender: 0.5862, Loss Profession: 1.1616\nEpoch [139/150], Loss Gender: 0.5850, Loss Profession: 1.1621\nEpoch [140/150], Loss Gender: 0.5860, Loss Profession: 1.1568\nEpoch [141/150], Loss Gender: 0.5855, Loss Profession: 1.1578\nEpoch [142/150], Loss Gender: 0.5847, Loss Profession: 1.1548\nEpoch [143/150], Loss Gender: 0.5859, Loss Profession: 1.1527\nEpoch [144/150], Loss Gender: 0.5840, Loss Profession: 1.1513\nEpoch [145/150], Loss Gender: 0.5860, Loss Profession: 1.1488\nEpoch [146/150], Loss Gender: 0.5835, Loss Profession: 1.1509\nEpoch [147/150], Loss Gender: 0.5829, Loss Profession: 1.1481\nEpoch [148/150], Loss Gender: 0.5820, Loss Profession: 1.1439\nEpoch [149/150], Loss Gender: 0.5824, Loss Profession: 1.1368\nEpoch [150/150], Loss Gender: 0.5825, Loss Profession: 1.1390\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndef evaluate_multitask_model(model, test_loader):\n    model.eval()\n    correct_gender = 0\n    correct_profession = 0\n    total = 0\n    with torch.no_grad():\n        for batch_X, batch_Y_gender, batch_Y_profession in test_loader:\n            outputs_gender, outputs_profession = model(batch_X)\n            _, predicted_gender = torch.max(outputs_gender.data, 1)\n            _, predicted_profession = torch.max(outputs_profession.data, 1)\n            total += batch_Y_gender.size(0)\n            correct_gender += (predicted_gender == batch_Y_gender).sum().item()\n            correct_profession += (predicted_profession == batch_Y_profession).sum().item()\n    \n    accuracy_gender = 100 * correct_gender / total\n    accuracy_profession = 100 * correct_profession / total\n    return accuracy_gender, accuracy_profession\n\n# Evaluate the multitask model\nX_test_tensor = torch.tensor(X_test, dtype=torch.float32)\nY_test_tensor = torch.tensor(Y_test, dtype=torch.long)\nprofession_test_tensor = torch.tensor(profession_test, dtype=torch.long)\n\ntest_dataset_multitask = TensorDataset(X_test_tensor, Y_test_tensor, profession_test_tensor)\ntest_loader_multitask = DataLoader(test_dataset_multitask, batch_size=32, shuffle=False)\n\naccuracy_gender, accuracy_profession = evaluate_multitask_model(model_multitask, test_loader_multitask)\nprint(f\"Gender Prediction Accuracy: {accuracy_gender:.2f}%\")\nprint(f\"Profession Prediction Accuracy: {accuracy_profession:.2f}%\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-10T04:21:17.068080Z","iopub.execute_input":"2024-06-10T04:21:17.068754Z","iopub.status.idle":"2024-06-10T04:21:17.144748Z","shell.execute_reply.started":"2024-06-10T04:21:17.068705Z","shell.execute_reply":"2024-06-10T04:21:17.143856Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Gender Prediction Accuracy: 63.50%\nProfession Prediction Accuracy: 70.70%\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport numpy as np\n\nclass RateDistortion(nn.Module):\n    def __init__(self, gam1=1.0, gam2=1.0, eps=0.01):\n        super(RateDistortion, self).__init__()\n        self.gam1 = gam1\n        self.gam2 = gam2\n        self.eps = eps\n\n    def rate(self, W):\n        p, m = W.shape\n        I = torch.eye(p).to(W.device)\n        scalar = p / (m * self.eps)\n        logdet = torch.logdet(I + self.gam1 * scalar * W.matmul(W.T))\n        return logdet / 2.0\n\n    def rate_for_continuous(self, W, kernel):\n        p, m = W.shape\n        I = torch.eye(p).to(W.device)\n        scalar = p / (m * self.eps)\n        cov = W.matmul(W.T)\n        kernelized_cov = torch.mul(cov, kernel)\n        logdet = torch.logdet(I + self.gam1 * scalar * kernelized_cov)\n        return logdet / 2.0\n\n    def forward(self, X, X_raw, kernel, scale=1.0):\n        const = self.rate(X_raw.T)\n        R_z = self.rate(X.T)\n        eq_const = torch.abs(R_z - scale * const)\n        R_z_K = self.rate_for_continuous(X, kernel)\n        return -R_z_K, eq_const\n\ndef gaussian_kernel(tensor, sigma=0.1):\n    protected_var = tensor.view(-1, 1)\n    pairwise_dist = torch.cdist(protected_var, protected_var)\n    kernel = torch.exp(-pairwise_dist / sigma)\n    return kernel\n","metadata":{"execution":{"iopub.status.busy":"2024-06-10T04:22:17.756666Z","iopub.execute_input":"2024-06-10T04:22:17.757383Z","iopub.status.idle":"2024-06-10T04:22:17.767885Z","shell.execute_reply.started":"2024-06-10T04:22:17.757351Z","shell.execute_reply":"2024-06-10T04:22:17.766926Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"class MultitaskMLPWithErasure(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size_gender, output_size_profession):\n        super(MultitaskMLPWithErasure, self).__init__()\n        self.shared_fc1 = nn.Linear(input_size, hidden_size)\n        self.shared_bn1 = nn.BatchNorm1d(hidden_size)\n        self.shared_relu = nn.ReLU()\n        self.fc_gender = nn.Linear(hidden_size, output_size_gender)\n        self.fc_profession = nn.Linear(hidden_size, output_size_profession)\n        self.rate_distortion = RateDistortion()\n\n    def forward(self, x, gender_labels=None, sigma=0.1):\n        x = self.shared_fc1(x)\n        x = self.shared_bn1(x)\n        x = self.shared_relu(x)\n        \n        if self.training and gender_labels is not None:\n            kernel = gaussian_kernel(gender_labels, sigma=sigma)\n            Rzk, eq_const = self.rate_distortion(x, x, kernel)\n            self.gender_erasure_loss = Rzk + eq_const\n        else:\n            self.gender_erasure_loss = None\n\n        gender_output = self.fc_gender(x)\n        profession_output = self.fc_profession(x)\n        return gender_output, profession_output\n","metadata":{"execution":{"iopub.status.busy":"2024-06-10T04:22:23.925706Z","iopub.execute_input":"2024-06-10T04:22:23.926669Z","iopub.status.idle":"2024-06-10T04:22:23.935217Z","shell.execute_reply.started":"2024-06-10T04:22:23.926626Z","shell.execute_reply":"2024-06-10T04:22:23.934351Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def train_multitask_model_with_erasure(model, train_loader, criterion_gender, criterion_profession, optimizer, num_epochs=10, sigma=0.1):\n    model.train()\n    for epoch in range(num_epochs):\n        total_loss_gender = 0\n        total_loss_profession = 0\n        total_loss_erasure = 0\n        \n        for batch_X, batch_Y_gender, batch_Y_profession in train_loader:\n            # Ensure inputs are float\n#             batch_X = batch_X.float()\n#             # Convert labels to long\n#             batch_Y_gender = batch_Y_gender.long()\n#             batch_Y_profession = batch_Y_profession.long()\n\n            optimizer.zero_grad()\n            outputs_gender, outputs_profession = model(batch_X.float(), gender_labels=batch_Y_gender.float(), sigma=sigma)\n            loss_gender = criterion_gender(outputs_gender, batch_Y_gender)\n            loss_profession = criterion_profession(outputs_profession, batch_Y_profession)\n            \n            if model.gender_erasure_loss is not None:\n                total_loss = loss_profession + model.gender_erasure_loss\n                total_loss_erasure += model.gender_erasure_loss.item()\n            else:\n                total_loss = loss_gender + loss_profession\n            \n            total_loss.backward()\n            optimizer.step()\n            total_loss_gender += loss_gender.item()\n            total_loss_profession += loss_profession.item()\n        \n        avg_loss_gender = total_loss_gender / len(train_loader)\n        avg_loss_profession = total_loss_profession / len(train_loader)\n        avg_loss_erasure = total_loss_erasure / len(train_loader)\n        \n        print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n              f\"Loss Gender: {avg_loss_gender:.4f}, \"\n              f\"Loss Profession: {avg_loss_profession:.4f}, \"\n              f\"Loss Erasure: {avg_loss_erasure:.4f}\")\n\n# Assuming `model_multitask` is the trained model\nmodel_multitask_erased = MultitaskMLPWithErasure(input_size, hidden_size, output_size_gender, output_size_profession)\nmodel_multitask_erased.load_state_dict(model_multitask.state_dict())\n\noptimizer_multitask_erased = optim.SGD(model_multitask_erased.parameters(), lr=0.001)\ntrain_multitask_model_with_erasure(model_multitask_erased, train_loader_multitask, criterion_gender, criterion_profession, optimizer_multitask_erased, num_epochs=200, sigma=0.1)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-10T05:01:54.946665Z","iopub.execute_input":"2024-06-10T05:01:54.947388Z","iopub.status.idle":"2024-06-10T05:05:38.336894Z","shell.execute_reply.started":"2024-06-10T05:01:54.947358Z","shell.execute_reply":"2024-06-10T05:05:38.335974Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Epoch [1/200], Loss Gender: 0.6280, Loss Profession: 1.1982, Loss Erasure: -119.2146\nEpoch [2/200], Loss Gender: 0.7018, Loss Profession: 1.2417, Loss Erasure: -128.0236\nEpoch [3/200], Loss Gender: 0.7500, Loss Profession: 1.2485, Loss Erasure: -133.5230\nEpoch [4/200], Loss Gender: 0.7902, Loss Profession: 1.2555, Loss Erasure: -137.6376\nEpoch [5/200], Loss Gender: 0.8368, Loss Profession: 1.2461, Loss Erasure: -140.9555\nEpoch [6/200], Loss Gender: 0.8828, Loss Profession: 1.2422, Loss Erasure: -143.6658\nEpoch [7/200], Loss Gender: 0.9171, Loss Profession: 1.2449, Loss Erasure: -146.0175\nEpoch [8/200], Loss Gender: 0.9439, Loss Profession: 1.2353, Loss Erasure: -148.0560\nEpoch [9/200], Loss Gender: 0.9935, Loss Profession: 1.2276, Loss Erasure: -149.8381\nEpoch [10/200], Loss Gender: 1.0204, Loss Profession: 1.2286, Loss Erasure: -151.5895\nEpoch [11/200], Loss Gender: 1.0429, Loss Profession: 1.2209, Loss Erasure: -152.9623\nEpoch [12/200], Loss Gender: 1.0966, Loss Profession: 1.2082, Loss Erasure: -154.3186\nEpoch [13/200], Loss Gender: 1.1321, Loss Profession: 1.1952, Loss Erasure: -155.6389\nEpoch [14/200], Loss Gender: 1.1613, Loss Profession: 1.2028, Loss Erasure: -156.7950\nEpoch [15/200], Loss Gender: 1.1901, Loss Profession: 1.1879, Loss Erasure: -157.8679\nEpoch [16/200], Loss Gender: 1.2486, Loss Profession: 1.1903, Loss Erasure: -158.8857\nEpoch [17/200], Loss Gender: 1.2588, Loss Profession: 1.1839, Loss Erasure: -159.8384\nEpoch [18/200], Loss Gender: 1.2915, Loss Profession: 1.1828, Loss Erasure: -160.8400\nEpoch [19/200], Loss Gender: 1.3393, Loss Profession: 1.1662, Loss Erasure: -161.6911\nEpoch [20/200], Loss Gender: 1.3642, Loss Profession: 1.1685, Loss Erasure: -162.4714\nEpoch [21/200], Loss Gender: 1.3849, Loss Profession: 1.1660, Loss Erasure: -163.1746\nEpoch [22/200], Loss Gender: 1.4337, Loss Profession: 1.1708, Loss Erasure: -163.9395\nEpoch [23/200], Loss Gender: 1.4495, Loss Profession: 1.1527, Loss Erasure: -164.7047\nEpoch [24/200], Loss Gender: 1.4617, Loss Profession: 1.1484, Loss Erasure: -165.4649\nEpoch [25/200], Loss Gender: 1.4893, Loss Profession: 1.1494, Loss Erasure: -166.0191\nEpoch [26/200], Loss Gender: 1.5200, Loss Profession: 1.1496, Loss Erasure: -166.7324\nEpoch [27/200], Loss Gender: 1.5658, Loss Profession: 1.1517, Loss Erasure: -167.2124\nEpoch [28/200], Loss Gender: 1.5857, Loss Profession: 1.1541, Loss Erasure: -167.8492\nEpoch [29/200], Loss Gender: 1.6042, Loss Profession: 1.1422, Loss Erasure: -168.4493\nEpoch [30/200], Loss Gender: 1.6437, Loss Profession: 1.1419, Loss Erasure: -169.0147\nEpoch [31/200], Loss Gender: 1.6504, Loss Profession: 1.1430, Loss Erasure: -169.5958\nEpoch [32/200], Loss Gender: 1.6792, Loss Profession: 1.1252, Loss Erasure: -170.0123\nEpoch [33/200], Loss Gender: 1.7256, Loss Profession: 1.1461, Loss Erasure: -170.4492\nEpoch [34/200], Loss Gender: 1.7346, Loss Profession: 1.1423, Loss Erasure: -171.0135\nEpoch [35/200], Loss Gender: 1.7598, Loss Profession: 1.1327, Loss Erasure: -171.4886\nEpoch [36/200], Loss Gender: 1.8011, Loss Profession: 1.1338, Loss Erasure: -171.8601\nEpoch [37/200], Loss Gender: 1.8048, Loss Profession: 1.1281, Loss Erasure: -172.3606\nEpoch [38/200], Loss Gender: 1.8419, Loss Profession: 1.1294, Loss Erasure: -172.7680\nEpoch [39/200], Loss Gender: 1.8651, Loss Profession: 1.1246, Loss Erasure: -173.2358\nEpoch [40/200], Loss Gender: 1.8721, Loss Profession: 1.1249, Loss Erasure: -173.6407\nEpoch [41/200], Loss Gender: 1.8928, Loss Profession: 1.1395, Loss Erasure: -174.0130\nEpoch [42/200], Loss Gender: 1.9127, Loss Profession: 1.1359, Loss Erasure: -174.4986\nEpoch [43/200], Loss Gender: 1.9299, Loss Profession: 1.1281, Loss Erasure: -174.8053\nEpoch [44/200], Loss Gender: 1.9694, Loss Profession: 1.1336, Loss Erasure: -175.1557\nEpoch [45/200], Loss Gender: 1.9756, Loss Profession: 1.1372, Loss Erasure: -175.5032\nEpoch [46/200], Loss Gender: 2.0043, Loss Profession: 1.1288, Loss Erasure: -175.7991\nEpoch [47/200], Loss Gender: 2.0511, Loss Profession: 1.1190, Loss Erasure: -176.1983\nEpoch [48/200], Loss Gender: 2.0104, Loss Profession: 1.1204, Loss Erasure: -176.6519\nEpoch [49/200], Loss Gender: 2.0298, Loss Profession: 1.1331, Loss Erasure: -176.9529\nEpoch [50/200], Loss Gender: 2.0781, Loss Profession: 1.1283, Loss Erasure: -177.2226\nEpoch [51/200], Loss Gender: 2.0707, Loss Profession: 1.1358, Loss Erasure: -177.4876\nEpoch [52/200], Loss Gender: 2.1007, Loss Profession: 1.1315, Loss Erasure: -177.9216\nEpoch [53/200], Loss Gender: 2.1192, Loss Profession: 1.1369, Loss Erasure: -178.1483\nEpoch [54/200], Loss Gender: 2.1406, Loss Profession: 1.1249, Loss Erasure: -178.4997\nEpoch [55/200], Loss Gender: 2.1343, Loss Profession: 1.1368, Loss Erasure: -178.7624\nEpoch [56/200], Loss Gender: 2.1604, Loss Profession: 1.1383, Loss Erasure: -179.0191\nEpoch [57/200], Loss Gender: 2.1989, Loss Profession: 1.1395, Loss Erasure: -179.4478\nEpoch [58/200], Loss Gender: 2.2071, Loss Profession: 1.1274, Loss Erasure: -179.6261\nEpoch [59/200], Loss Gender: 2.2470, Loss Profession: 1.1313, Loss Erasure: -179.9784\nEpoch [60/200], Loss Gender: 2.2316, Loss Profession: 1.1346, Loss Erasure: -180.1843\nEpoch [61/200], Loss Gender: 2.2876, Loss Profession: 1.1416, Loss Erasure: -180.4225\nEpoch [62/200], Loss Gender: 2.3170, Loss Profession: 1.1523, Loss Erasure: -180.7352\nEpoch [63/200], Loss Gender: 2.3017, Loss Profession: 1.1310, Loss Erasure: -180.9602\nEpoch [64/200], Loss Gender: 2.3329, Loss Profession: 1.1479, Loss Erasure: -181.2769\nEpoch [65/200], Loss Gender: 2.3406, Loss Profession: 1.1331, Loss Erasure: -181.4213\nEpoch [66/200], Loss Gender: 2.3624, Loss Profession: 1.1415, Loss Erasure: -181.6793\nEpoch [67/200], Loss Gender: 2.3853, Loss Profession: 1.1438, Loss Erasure: -181.9595\nEpoch [68/200], Loss Gender: 2.4149, Loss Profession: 1.1430, Loss Erasure: -182.2730\nEpoch [69/200], Loss Gender: 2.4502, Loss Profession: 1.1358, Loss Erasure: -182.4576\nEpoch [70/200], Loss Gender: 2.4670, Loss Profession: 1.1278, Loss Erasure: -182.6971\nEpoch [71/200], Loss Gender: 2.4719, Loss Profession: 1.1545, Loss Erasure: -182.8907\nEpoch [72/200], Loss Gender: 2.4443, Loss Profession: 1.1495, Loss Erasure: -183.1091\nEpoch [73/200], Loss Gender: 2.5150, Loss Profession: 1.1582, Loss Erasure: -183.4261\nEpoch [74/200], Loss Gender: 2.5433, Loss Profession: 1.1393, Loss Erasure: -183.5693\nEpoch [75/200], Loss Gender: 2.5282, Loss Profession: 1.1414, Loss Erasure: -183.7425\nEpoch [76/200], Loss Gender: 2.5151, Loss Profession: 1.1651, Loss Erasure: -184.0288\nEpoch [77/200], Loss Gender: 2.5703, Loss Profession: 1.1453, Loss Erasure: -184.2792\nEpoch [78/200], Loss Gender: 2.5733, Loss Profession: 1.1511, Loss Erasure: -184.4454\nEpoch [79/200], Loss Gender: 2.5607, Loss Profession: 1.1649, Loss Erasure: -184.5890\nEpoch [80/200], Loss Gender: 2.6107, Loss Profession: 1.1472, Loss Erasure: -184.8221\nEpoch [81/200], Loss Gender: 2.6128, Loss Profession: 1.1407, Loss Erasure: -185.0533\nEpoch [82/200], Loss Gender: 2.6642, Loss Profession: 1.1601, Loss Erasure: -185.2708\nEpoch [83/200], Loss Gender: 2.6312, Loss Profession: 1.1531, Loss Erasure: -185.4004\nEpoch [84/200], Loss Gender: 2.6615, Loss Profession: 1.1832, Loss Erasure: -185.5635\nEpoch [85/200], Loss Gender: 2.6876, Loss Profession: 1.1771, Loss Erasure: -185.8420\nEpoch [86/200], Loss Gender: 2.7227, Loss Profession: 1.1641, Loss Erasure: -185.9898\nEpoch [87/200], Loss Gender: 2.7535, Loss Profession: 1.1708, Loss Erasure: -186.2133\nEpoch [88/200], Loss Gender: 2.7489, Loss Profession: 1.1764, Loss Erasure: -186.3869\nEpoch [89/200], Loss Gender: 2.8015, Loss Profession: 1.1712, Loss Erasure: -186.4997\nEpoch [90/200], Loss Gender: 2.8113, Loss Profession: 1.1740, Loss Erasure: -186.8027\nEpoch [91/200], Loss Gender: 2.7816, Loss Profession: 1.1768, Loss Erasure: -186.7547\nEpoch [92/200], Loss Gender: 2.8031, Loss Profession: 1.1767, Loss Erasure: -187.0672\nEpoch [93/200], Loss Gender: 2.8334, Loss Profession: 1.1773, Loss Erasure: -187.2327\nEpoch [94/200], Loss Gender: 2.8598, Loss Profession: 1.1777, Loss Erasure: -187.3820\nEpoch [95/200], Loss Gender: 2.8362, Loss Profession: 1.1883, Loss Erasure: -187.5770\nEpoch [96/200], Loss Gender: 2.8475, Loss Profession: 1.1803, Loss Erasure: -187.7815\nEpoch [97/200], Loss Gender: 2.8627, Loss Profession: 1.1877, Loss Erasure: -188.0048\nEpoch [98/200], Loss Gender: 2.8759, Loss Profession: 1.2005, Loss Erasure: -188.0786\nEpoch [99/200], Loss Gender: 2.9091, Loss Profession: 1.2030, Loss Erasure: -188.2769\nEpoch [100/200], Loss Gender: 2.9176, Loss Profession: 1.1755, Loss Erasure: -188.4756\nEpoch [101/200], Loss Gender: 2.9239, Loss Profession: 1.2084, Loss Erasure: -188.6815\nEpoch [102/200], Loss Gender: 2.9872, Loss Profession: 1.1851, Loss Erasure: -188.6747\nEpoch [103/200], Loss Gender: 2.9934, Loss Profession: 1.2073, Loss Erasure: -188.9226\nEpoch [104/200], Loss Gender: 2.9989, Loss Profession: 1.1889, Loss Erasure: -189.0073\nEpoch [105/200], Loss Gender: 3.0144, Loss Profession: 1.2064, Loss Erasure: -189.2544\nEpoch [106/200], Loss Gender: 3.0112, Loss Profession: 1.2103, Loss Erasure: -189.3700\nEpoch [107/200], Loss Gender: 3.0389, Loss Profession: 1.1881, Loss Erasure: -189.5561\nEpoch [108/200], Loss Gender: 3.0478, Loss Profession: 1.2178, Loss Erasure: -189.6264\nEpoch [109/200], Loss Gender: 3.0900, Loss Profession: 1.2127, Loss Erasure: -189.8679\nEpoch [110/200], Loss Gender: 3.0774, Loss Profession: 1.2313, Loss Erasure: -189.9639\nEpoch [111/200], Loss Gender: 3.0996, Loss Profession: 1.2313, Loss Erasure: -189.9828\nEpoch [112/200], Loss Gender: 3.0942, Loss Profession: 1.2166, Loss Erasure: -190.1981\nEpoch [113/200], Loss Gender: 3.1367, Loss Profession: 1.2412, Loss Erasure: -190.3359\nEpoch [114/200], Loss Gender: 3.1518, Loss Profession: 1.2322, Loss Erasure: -190.5572\nEpoch [115/200], Loss Gender: 3.1576, Loss Profession: 1.2134, Loss Erasure: -190.6529\nEpoch [116/200], Loss Gender: 3.1660, Loss Profession: 1.2506, Loss Erasure: -190.7570\nEpoch [117/200], Loss Gender: 3.2106, Loss Profession: 1.2425, Loss Erasure: -190.9328\nEpoch [118/200], Loss Gender: 3.2206, Loss Profession: 1.2380, Loss Erasure: -191.0360\nEpoch [119/200], Loss Gender: 3.2646, Loss Profession: 1.2439, Loss Erasure: -191.1290\nEpoch [120/200], Loss Gender: 3.2606, Loss Profession: 1.2440, Loss Erasure: -191.2417\nEpoch [121/200], Loss Gender: 3.2625, Loss Profession: 1.2501, Loss Erasure: -191.4415\nEpoch [122/200], Loss Gender: 3.2562, Loss Profession: 1.2711, Loss Erasure: -191.5249\nEpoch [123/200], Loss Gender: 3.2776, Loss Profession: 1.2466, Loss Erasure: -191.7947\nEpoch [124/200], Loss Gender: 3.2821, Loss Profession: 1.2621, Loss Erasure: -191.7693\nEpoch [125/200], Loss Gender: 3.2976, Loss Profession: 1.2639, Loss Erasure: -191.9806\nEpoch [126/200], Loss Gender: 3.2817, Loss Profession: 1.2451, Loss Erasure: -192.0873\nEpoch [127/200], Loss Gender: 3.3097, Loss Profession: 1.2567, Loss Erasure: nan\nEpoch [128/200], Loss Gender: 3.3066, Loss Profession: 1.2828, Loss Erasure: -192.3988\nEpoch [129/200], Loss Gender: 3.3646, Loss Profession: 1.2942, Loss Erasure: -192.5472\nEpoch [130/200], Loss Gender: 3.3273, Loss Profession: 1.2808, Loss Erasure: nan\nEpoch [131/200], Loss Gender: 3.3696, Loss Profession: 1.2794, Loss Erasure: nan\nEpoch [132/200], Loss Gender: 3.3639, Loss Profession: 1.2704, Loss Erasure: nan\nEpoch [133/200], Loss Gender: 3.3951, Loss Profession: 1.2870, Loss Erasure: nan\nEpoch [134/200], Loss Gender: 3.4255, Loss Profession: 1.2967, Loss Erasure: nan\nEpoch [135/200], Loss Gender: 3.4327, Loss Profession: 1.2984, Loss Erasure: nan\nEpoch [136/200], Loss Gender: 3.4795, Loss Profession: 1.2880, Loss Erasure: nan\nEpoch [137/200], Loss Gender: 3.4725, Loss Profession: 1.2944, Loss Erasure: nan\nEpoch [138/200], Loss Gender: 3.4575, Loss Profession: 1.2861, Loss Erasure: nan\nEpoch [139/200], Loss Gender: 3.4651, Loss Profession: 1.2965, Loss Erasure: nan\nEpoch [140/200], Loss Gender: 3.5258, Loss Profession: 1.2740, Loss Erasure: nan\nEpoch [141/200], Loss Gender: 3.5754, Loss Profession: 1.3035, Loss Erasure: nan\nEpoch [142/200], Loss Gender: 3.5423, Loss Profession: 1.3254, Loss Erasure: nan\nEpoch [143/200], Loss Gender: 3.5151, Loss Profession: 1.3034, Loss Erasure: nan\nEpoch [144/200], Loss Gender: 3.5763, Loss Profession: 1.3055, Loss Erasure: nan\nEpoch [145/200], Loss Gender: 3.5575, Loss Profession: 1.3163, Loss Erasure: nan\nEpoch [146/200], Loss Gender: 3.5931, Loss Profession: 1.3076, Loss Erasure: nan\nEpoch [147/200], Loss Gender: 3.6225, Loss Profession: 1.3090, Loss Erasure: nan\nEpoch [148/200], Loss Gender: 3.6180, Loss Profession: 1.3272, Loss Erasure: nan\nEpoch [149/200], Loss Gender: 3.6030, Loss Profession: 1.3554, Loss Erasure: nan\nEpoch [150/200], Loss Gender: 3.6418, Loss Profession: 1.3393, Loss Erasure: nan\nEpoch [151/200], Loss Gender: 3.6711, Loss Profession: 1.3419, Loss Erasure: nan\nEpoch [152/200], Loss Gender: 3.6486, Loss Profession: 1.3326, Loss Erasure: nan\nEpoch [153/200], Loss Gender: 3.7184, Loss Profession: 1.3590, Loss Erasure: nan\nEpoch [154/200], Loss Gender: 3.6603, Loss Profession: 1.3331, Loss Erasure: nan\nEpoch [155/200], Loss Gender: 3.7365, Loss Profession: 1.3665, Loss Erasure: nan\nEpoch [156/200], Loss Gender: 3.7228, Loss Profession: 1.3452, Loss Erasure: nan\nEpoch [157/200], Loss Gender: 3.7531, Loss Profession: 1.3698, Loss Erasure: nan\nEpoch [158/200], Loss Gender: 3.7738, Loss Profession: 1.3836, Loss Erasure: nan\nEpoch [159/200], Loss Gender: 3.7451, Loss Profession: 1.3582, Loss Erasure: nan\nEpoch [160/200], Loss Gender: 3.7722, Loss Profession: 1.3558, Loss Erasure: nan\nEpoch [161/200], Loss Gender: 3.7466, Loss Profession: 1.3399, Loss Erasure: nan\nEpoch [162/200], Loss Gender: 3.7595, Loss Profession: 1.3568, Loss Erasure: nan\nEpoch [163/200], Loss Gender: 3.8247, Loss Profession: 1.4033, Loss Erasure: nan\nEpoch [164/200], Loss Gender: 3.8415, Loss Profession: 1.3909, Loss Erasure: nan\nEpoch [165/200], Loss Gender: 3.8383, Loss Profession: 1.4102, Loss Erasure: nan\nEpoch [166/200], Loss Gender: 3.8785, Loss Profession: 1.4080, Loss Erasure: nan\nEpoch [167/200], Loss Gender: 3.8778, Loss Profession: 1.3726, Loss Erasure: nan\nEpoch [168/200], Loss Gender: 3.8554, Loss Profession: 1.3486, Loss Erasure: nan\nEpoch [169/200], Loss Gender: 3.9046, Loss Profession: 1.3442, Loss Erasure: nan\nEpoch [170/200], Loss Gender: 3.9215, Loss Profession: 1.4056, Loss Erasure: nan\nEpoch [171/200], Loss Gender: 3.9217, Loss Profession: 1.3919, Loss Erasure: nan\nEpoch [172/200], Loss Gender: 3.9391, Loss Profession: 1.3760, Loss Erasure: nan\nEpoch [173/200], Loss Gender: 3.9911, Loss Profession: 1.3982, Loss Erasure: nan\nEpoch [174/200], Loss Gender: 3.9521, Loss Profession: 1.4190, Loss Erasure: nan\nEpoch [175/200], Loss Gender: 3.9430, Loss Profession: 1.4204, Loss Erasure: nan\nEpoch [176/200], Loss Gender: 3.9886, Loss Profession: 1.4488, Loss Erasure: nan\nEpoch [177/200], Loss Gender: 3.9237, Loss Profession: 1.4444, Loss Erasure: nan\nEpoch [178/200], Loss Gender: 3.9742, Loss Profession: 1.4386, Loss Erasure: nan\nEpoch [179/200], Loss Gender: 3.9981, Loss Profession: 1.4200, Loss Erasure: nan\nEpoch [180/200], Loss Gender: 4.0195, Loss Profession: 1.4307, Loss Erasure: nan\nEpoch [181/200], Loss Gender: 4.0222, Loss Profession: 1.4104, Loss Erasure: nan\nEpoch [182/200], Loss Gender: 4.0231, Loss Profession: 1.4893, Loss Erasure: nan\nEpoch [183/200], Loss Gender: 4.0802, Loss Profession: 1.4296, Loss Erasure: nan\nEpoch [184/200], Loss Gender: 4.1071, Loss Profession: 1.4402, Loss Erasure: nan\nEpoch [185/200], Loss Gender: 4.0519, Loss Profession: 1.4701, Loss Erasure: nan\nEpoch [186/200], Loss Gender: 4.1012, Loss Profession: 1.4453, Loss Erasure: nan\nEpoch [187/200], Loss Gender: 4.0818, Loss Profession: 1.4790, Loss Erasure: nan\nEpoch [188/200], Loss Gender: 4.0850, Loss Profession: 1.4904, Loss Erasure: nan\nEpoch [189/200], Loss Gender: 4.0918, Loss Profession: 1.5020, Loss Erasure: nan\nEpoch [190/200], Loss Gender: 4.1162, Loss Profession: 1.4943, Loss Erasure: nan\nEpoch [191/200], Loss Gender: 4.0369, Loss Profession: 1.4817, Loss Erasure: nan\nEpoch [192/200], Loss Gender: 4.0762, Loss Profession: 1.4647, Loss Erasure: nan\nEpoch [193/200], Loss Gender: 4.1509, Loss Profession: 1.4677, Loss Erasure: nan\nEpoch [194/200], Loss Gender: 4.1942, Loss Profession: 1.4674, Loss Erasure: nan\nEpoch [195/200], Loss Gender: 4.1833, Loss Profession: 1.4499, Loss Erasure: nan\nEpoch [196/200], Loss Gender: 4.1610, Loss Profession: 1.5286, Loss Erasure: nan\nEpoch [197/200], Loss Gender: 4.2116, Loss Profession: 1.4525, Loss Erasure: nan\nEpoch [198/200], Loss Gender: 4.2168, Loss Profession: 1.5533, Loss Erasure: nan\nEpoch [199/200], Loss Gender: 4.1511, Loss Profession: 1.4954, Loss Erasure: nan\nEpoch [200/200], Loss Gender: 4.1885, Loss Profession: 1.5243, Loss Erasure: nan\n","output_type":"stream"}]},{"cell_type":"code","source":"def evaluate_multitask_model_with_erasure(model, test_loader):\n    model.eval()\n    correct_gender = 0\n    correct_profession = 0\n    total = 0\n    \n    with torch.no_grad():\n        for batch_X, batch_Y_gender, batch_Y_profession in test_loader:\n            outputs_gender, outputs_profession = model(batch_X)\n            _, predicted_gender = torch.max(outputs_gender.data, 1)\n            _, predicted_profession = torch.max(outputs_profession.data, 1)\n            total += batch_Y_gender.size(0)\n            correct_gender += (predicted_gender == batch_Y_gender).sum().item()\n            correct_profession += (predicted_profession == batch_Y_profession).sum().item()\n    \n    accuracy_gender = 100 * correct_gender / total\n    accuracy_profession = 100 * correct_profession / total\n    return accuracy_gender, accuracy_profession\n\n# Evaluate the model after concept erasure\naccuracy_gender_erased, accuracy_profession_erased = evaluate_multitask_model_with_erasure(model_multitask_erased, test_loader_multitask)\nprint(f\"Gender Prediction Accuracy After Erasure: {accuracy_gender_erased:.2f}%\")\nprint(f\"Profession Prediction Accuracy After Erasure: {accuracy_profession_erased:.2f}%\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-10T05:06:42.562187Z","iopub.execute_input":"2024-06-10T05:06:42.562822Z","iopub.status.idle":"2024-06-10T05:06:42.629585Z","shell.execute_reply.started":"2024-06-10T05:06:42.562790Z","shell.execute_reply":"2024-06-10T05:06:42.628682Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Gender Prediction Accuracy After Erasure: 54.55%\nProfession Prediction Accuracy After Erasure: 64.55%\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-06-09T19:06:11.755360Z","iopub.execute_input":"2024-06-09T19:06:11.755708Z","iopub.status.idle":"2024-06-09T19:06:11.763303Z","shell.execute_reply.started":"2024-06-09T19:06:11.755683Z","shell.execute_reply":"2024-06-09T19:06:11.762212Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-06-09T19:14:14.062659Z","iopub.execute_input":"2024-06-09T19:14:14.063589Z","iopub.status.idle":"2024-06-09T19:14:14.309404Z","shell.execute_reply.started":"2024-06-09T19:14:14.063554Z","shell.execute_reply":"2024-06-09T19:14:14.308119Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":33,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[33], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Calculate loss\u001b[39;00m\n\u001b[1;32m     17\u001b[0m loss_profession \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()(profession_output, y_prof)\n\u001b[0;32m---> 18\u001b[0m loss_distortion \u001b[38;5;241m=\u001b[39m criterion(\u001b[43mmodel_multitask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m(data), y_gender)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Total loss\u001b[39;00m\n\u001b[1;32m     21\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m loss_profession \u001b[38;5;241m+\u001b[39m loss_distortion\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mAttributeError\u001b[0m: 'MultitaskMLP' object has no attribute 'features'"],"ename":"AttributeError","evalue":"'MultitaskMLP' object has no attribute 'features'","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-06-09T19:05:56.808244Z","iopub.execute_input":"2024-06-09T19:05:56.808629Z","iopub.status.idle":"2024-06-09T19:05:56.853401Z","shell.execute_reply.started":"2024-06-09T19:05:56.808601Z","shell.execute_reply":"2024-06-09T19:05:56.852268Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":27,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[27], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGender Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m100\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39mgender_correct\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39mgender_total\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m evaluate_model(model_multitask, \u001b[43mtest_dataloader\u001b[49m)\n","\u001b[0;31mNameError\u001b[0m: name 'test_dataloader' is not defined"],"ename":"NameError","evalue":"name 'test_dataloader' is not defined","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-06-09T18:57:34.468019Z","iopub.execute_input":"2024-06-09T18:57:34.468405Z","iopub.status.idle":"2024-06-09T18:57:34.482141Z","shell.execute_reply.started":"2024-06-09T18:57:34.468370Z","shell.execute_reply":"2024-06-09T18:57:34.481269Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-06-09T18:57:40.510383Z","iopub.execute_input":"2024-06-09T18:57:40.510979Z","iopub.status.idle":"2024-06-09T18:57:40.519768Z","shell.execute_reply.started":"2024-06-09T18:57:40.510951Z","shell.execute_reply":"2024-06-09T18:57:40.518854Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-06-09T18:57:45.072075Z","iopub.execute_input":"2024-06-09T18:57:45.072931Z","iopub.status.idle":"2024-06-09T18:57:45.078838Z","shell.execute_reply.started":"2024-06-09T18:57:45.072899Z","shell.execute_reply":"2024-06-09T18:57:45.077848Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-06-09T18:35:52.752485Z","iopub.execute_input":"2024-06-09T18:35:52.753321Z","iopub.status.idle":"2024-06-09T18:35:59.950644Z","shell.execute_reply.started":"2024-06-09T18:35:52.753283Z","shell.execute_reply":"2024-06-09T18:35:59.949677Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Epoch [1/10], Loss: -53.7286\nEpoch [2/10], Loss: -60.8255\nEpoch [3/10], Loss: -53.3005\nEpoch [4/10], Loss: -71.1074\nEpoch [5/10], Loss: -64.1900\nEpoch [6/10], Loss: -58.9908\nEpoch [7/10], Loss: -54.1213\nEpoch [8/10], Loss: -67.3487\nEpoch [9/10], Loss: -69.3018\nEpoch [10/10], Loss: -53.5635\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-06-09T18:40:31.060069Z","iopub.execute_input":"2024-06-09T18:40:31.060452Z","iopub.status.idle":"2024-06-09T18:40:31.139109Z","shell.execute_reply.started":"2024-06-09T18:40:31.060422Z","shell.execute_reply":"2024-06-09T18:40:31.137907Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":20,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[20], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProfession Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprofession_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGender Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgender_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[20], line 13\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, dataloader)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     12\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[0;32m---> 13\u001b[0m     profession_preds \u001b[38;5;241m=\u001b[39m \u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprofession\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     14\u001b[0m     gender_preds \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     16\u001b[0m     _, profession_preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(profession_preds, \u001b[38;5;241m1\u001b[39m)\n","\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"],"ename":"IndexError","evalue":"too many indices for tensor of dimension 2","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}